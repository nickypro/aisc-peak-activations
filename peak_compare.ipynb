{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak Comparisons\n",
    "Comparing peak locations with mean locations and zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from taker import Model\n",
    "from taker.activations import get_midlayer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_offsets(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for mode calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Compute the mode across the last dimension for each neuron in every layer\n",
    "    #mode_values_float32, _ = torch.mode(activations_float32, dim=-1)\n",
    "    mode_values_float32 = torch.mean(activations_float32, dim=-1)\n",
    "    \n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        mode_values = mode_values_float32.half()\n",
    "    else:\n",
    "        mode_values = mode_values_float32\n",
    "    \n",
    "    # The mode_values tensor will have shape [layers, neurons], which is already 2D\n",
    "    # and matches the requirement of returning a 2D tensor of mode values.\n",
    "    \n",
    "    return mode_values\n",
    "\n",
    "def get_bucket_peaks(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for histogram calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Prepare for histogram computation\n",
    "    min_val = activations_float32.min()\n",
    "    max_val = activations_float32.max()\n",
    "    bins = 100\n",
    "\n",
    "    # Initialize an empty tensor to hold the peak values\n",
    "    peak_values_float32 = torch.empty(activations_float32.size()[:-1], device=activations_float32.device, dtype=torch.float32)\n",
    "    \n",
    "    # Compute the histogram and find the peak for each neuron in every layer\n",
    "    for i in range(activations_float32.size()[0]):  # Assuming the first dimension is layers\n",
    "        for j in range(activations_float32.size()[1]):  # Assuming the second dimension is neurons\n",
    "            #min_val = activations_float32[i, j].min()\n",
    "            #max_val = activations_float32[i, j].max()\n",
    "\n",
    "            hist = torch.histc(activations_float32[i, j], bins=bins, min=min_val, max=max_val)\n",
    "            peak_bin = hist.argmax()\n",
    "            # Compute the center value of the peak bin\n",
    "            bin_width = (max_val - min_val) / bins\n",
    "            peak_value = min_val + bin_width * (peak_bin.float() + 0.5)\n",
    "            peak_values_float32[i, j] = peak_value\n",
    "\n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        peak_values = peak_values_float32.half()\n",
    "    else:\n",
    "        peak_values = peak_values_float32\n",
    "\n",
    "    return peak_values\n",
    "\n",
    "def get_kde_peaks(activations, bandwidth=0.1):\n",
    "    layers, neurons, _ = activations.shape  # Assuming activations is a 3D tensor of shape [layers, neurons, activations]\n",
    "\n",
    "    # Initialize an empty tensor for main peak values with shape [layers, neurons]\n",
    "    main_peak_values = torch.empty((layers, neurons), dtype=torch.float32)\n",
    "\n",
    "    # Ensure activations are in float32 for KDE\n",
    "    if activations.dtype == torch.float16:\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Iterate over each layer and neuron to compute the main peak value\n",
    "    for layer in range(layers):\n",
    "        print(f\"Calculating KDE for layer {layer+1} of {layers}\")\n",
    "        for neuron in range(neurons):\n",
    "            # Convert activations to numpy for KDE computation\n",
    "            activations_np = activations_float32[layer, neuron].cpu().numpy().flatten()\n",
    "\n",
    "            # Perform Kernel Density Estimation\n",
    "            kde = stats.gaussian_kde(activations_np, bw_method=bandwidth)\n",
    "            \n",
    "            # Evaluate the KDE on a fine grid to find the peak\n",
    "            grid = np.linspace(activations_np.min(), activations_np.max(), 1000)\n",
    "            kde_values = kde.evaluate(grid)\n",
    "            \n",
    "            # Identify the main peak as the grid value with the highest KDE estimate\n",
    "            main_peak_value = grid[np.argmax(kde_values)]\n",
    "\n",
    "            # Store the main peak value\n",
    "            main_peak_values[layer, neuron] = main_peak_value\n",
    "\n",
    "    # No need to adjust activations here; just return the 2D tensor of main peak values\n",
    "    return main_peak_values\n",
    "\n",
    "def get_mode_offsets(activations):\n",
    "    # Check if the activations tensor is of type torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        # Convert to torch.float32 for mode calculation\n",
    "        activations_float32 = activations.float()\n",
    "    else:\n",
    "        # Use the original tensor if it's already in a supported data type\n",
    "        activations_float32 = activations\n",
    "\n",
    "    # Compute the mode across the last dimension for each neuron in every layer\n",
    "    mode_values_float32, _ = torch.mode(activations_float32, dim=-1)\n",
    "    #mode_values_float32 = torch.mean(activations_float32, dim=-1)\n",
    "    \n",
    "    # If the original tensor was torch.float16, convert the result back to torch.float16\n",
    "    if activations.dtype == torch.float16:\n",
    "        mode_values = mode_values_float32.half()\n",
    "    else:\n",
    "        mode_values = mode_values_float32\n",
    "    \n",
    "    # The mode_values tensor will have shape [layers, neurons], which is already 2D\n",
    "    # and matches the requirement of returning a 2D tensor of mode values.\n",
    "    \n",
    "    #flip the sign on everything since we are doing addition in the offset mask\n",
    "    #return mode_values * -1\n",
    "    return mode_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded facebook/opt-125m\n",
      " - Registered 12 Attention Layers\n"
     ]
    }
   ],
   "source": [
    "#opt = Model('facebook/opt-125m', limit=1000)\n",
    "#dataset = 'pile'\n",
    "\n",
    "opt = Model('google/vit-base-patch16-224', limit=1000, dtype='fp32')\n",
    "dataset = 'imagenet-1k-birdless'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f381ae8d1d4c2a9dcf929ef76853d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10311it [00:14, 690.10it/s]                            \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = get_midlayer_activations( opt, dataset, 1e4, collect_ff=False, collect_attn=True )\n",
    "#Â [token, layer, neuron] -> [layer, neuron, token]\n",
    "#ff_activations   = data.raw[\"ff\"].permute( (1,2,0) )\n",
    "# [token, layer, attention head, attention neuron] -> [layer, attention head, attention neuron, token]\n",
    "attn_activations = data.raw[\"attn\"].permute( (1,2,3,0) ).reshape( (opt.cfg.n_layers, opt.cfg.d_model, -1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "means = get_mean_offsets(attn_activations)\n",
    "peaks = get_bucket_peaks(attn_activations)\n",
    "\n",
    "#get the distance between the mean and the peak\n",
    "mean_peak_diff = torch.abs(means - peaks)\n",
    "\n",
    "#distance of means from 0\n",
    "peak_0_diff = torch.abs(means)\n",
    "\n",
    "#distance of peaks from 0\n",
    "mean_0_diff = torch.abs(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_peak_diff: 98.4375\n",
      "peak_0_diff: 112.0625\n",
      "mean_0_diff: 45.75\n"
     ]
    }
   ],
   "source": [
    "#print sums of all of the differences\n",
    "print(f\"mean_peak_diff: {mean_peak_diff.sum()}\")\n",
    "print(f\"peak_0_diff: {peak_0_diff.sum()}\")\n",
    "print(f\"mean_0_diff: {mean_0_diff.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peaks at 0: 0\n",
      "means at 0: 1037\n",
      "peaks size: torch.Size([12, 768])\n",
      "tensor([0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0427, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0834,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0427, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021, 0.0021,\n",
      "        0.0021], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "#TODO: how often is the peak at 0 (or really close)\n",
    "def num_peaks_at_zero(peaks, tolerance=0.001):\n",
    "    # Count how many numbers are within the tolerance of the target value\n",
    "    close_to_target = torch.abs(peaks) <= tolerance\n",
    "    return close_to_target.sum()\n",
    "\n",
    "print(f\"peaks at 0: {num_peaks_at_zero(peaks)}\")\n",
    "print(f\"means at 0: {num_peaks_at_zero(means)}\")\n",
    "\n",
    "#print size of peaks\n",
    "print(f\"peaks size: {peaks.size()}\")\n",
    "\n",
    "# print 100 peaks\n",
    "print(peaks[3, :100])\n",
    "\n",
    "#FIXME: are all of the peaks are basically the same because of how we are doing the bucketing?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
